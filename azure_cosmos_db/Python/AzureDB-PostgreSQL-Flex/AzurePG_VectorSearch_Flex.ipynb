{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Postgres Flex with vector search\n",
    "This sample shows how to use azure postgres (Flex) native vector search capabilities for RAG applications.  \n",
    "### Prerequisite: install python libraries\n",
    "- Please make sure all the libraries found in requirements.txt are installed in your python environment. \n",
    "- Rename example.env to llm.env and enter your credentials in llm_flex.env\n",
    "- Whitelist your IP to access your PostGres dv. Add you IP in \"Networking\" section of your PostGRes resource on the [Azure Portal](https://ms.portal.azure.com/)\n",
    "- To apply vector search, please install vector extensions for your db. You may follow this [link](https://learn.microsoft.com/en-us/azure/postgresql/flexible-server/concepts-extensions) to add vector to the allow-list of your db extensions.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load environment variables and keys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "\n",
    "# specify the name of the .env file name \n",
    "env_name = \"llm_flex.env\" # change to your own .env file name\n",
    "config = dotenv_values(env_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to Flex Postgres (PG) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection pool created successfully\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import pool\n",
    "\n",
    "host = config[\"host\"]\n",
    "dbname = config[\"dbname\"] \n",
    "user = config[\"user\"] \n",
    "password = config[\"password\"] \n",
    "sslmode = config[\"sslmode\"] \n",
    "\n",
    "# Build a connection string from the variables\n",
    "conn_string = \"host={0} user={1} dbname={2} password={3} sslmode={4}\".format(host, user, dbname, password, sslmode)\n",
    "\n",
    "postgreSQL_pool = psycopg2.pool.SimpleConnectionPool(1, 20,conn_string)\n",
    "if (postgreSQL_pool):\n",
    "    print(\"Connection pool created successfully\")\n",
    "\n",
    "# Use getconn() to get a connection from the connection pool\n",
    "connection = postgreSQL_pool.getconn()\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use pgvector, we need to first create the vector extension as described in this [link](https://learn.microsoft.com/en-us/azure/postgresql/flexible-server/how-to-use-pgvector) and shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a cursor to perform database operations\n",
    "# This is likely in case extension isn't already created from portal.\n",
    "cursor = connection.cursor()\n",
    "\n",
    "try:\n",
    "    # Start a new transaction\n",
    "    cursor.execute(\"BEGIN;\")\n",
    "\n",
    "    # Previous transaction statements\n",
    "    # ...\n",
    "\n",
    "    # Check if the extension already exists\n",
    "    extension_query = \"SELECT * FROM pg_extension WHERE extname = 'vector';\"\n",
    "    cursor.execute(extension_query)\n",
    "    extension_exists = cursor.fetchone()\n",
    "\n",
    "    if not extension_exists:\n",
    "        # Extension does not exist, create it\n",
    "        create_extension_query = \"CREATE EXTENSION vector;\"\n",
    "        cursor.execute(create_extension_query)\n",
    "        connection.commit()\n",
    "    else:\n",
    "        # Extension already exists, pass through\n",
    "        pass\n",
    "\n",
    "    # Commit the transaction\n",
    "    cursor.execute(\"COMMIT;\")\n",
    "except Exception as e:\n",
    "    # An error occurred, rollback the transaction\n",
    "    cursor.execute(\"ROLLBACK;\")\n",
    "    raise e\n",
    "finally:\n",
    "    # Close the cursor\n",
    "    cursor.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we will list the existing extensions for your db. Please make sure ['VECTOR'] IS listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('VECTOR',)\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Establish a connection to the database\n",
    "connection = psycopg2.connect(conn_string)\n",
    "\n",
    "# Open a cursor to perform database operations\n",
    "cursor = connection.cursor()\n",
    "\n",
    "\n",
    "\n",
    "# Define the SHOW EXTENSIONS query\n",
    "show_extensions_query = \"SHOW azure.extensions;\"\n",
    "\n",
    "# Execute the SHOW EXTENSIONS query\n",
    "cursor.execute(show_extensions_query)\n",
    "\n",
    "connection.commit()\n",
    "# Fetch and print the results\n",
    "results = cursor.fetchall()\n",
    "for row in results:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[OPTIONAL] You may run the following to list the existing tables in your db "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "food_reviews_vector_search\n",
      "food_reviews_vs\n",
      "food_reviews_vs2\n",
      "food_reviews_vs3\n"
     ]
    }
   ],
   "source": [
    "####### to get list of existing tables in the database\n",
    "# Create a cursor object to interact with the database\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Execute the SQL query to retrieve the table names\n",
    "cursor.execute(\"SELECT table_name FROM information_schema.tables WHERE table_schema='public'\")\n",
    "\n",
    "# Fetch all the results\n",
    "table_names = cursor.fetchall()\n",
    "\n",
    "# Print the table names\n",
    "for table in table_names:\n",
    "    print(table[0])\n",
    "    \n",
    "if not table_names:\n",
    "    print(\"No table found\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data and embedding to a table in the database\n",
    "In this section, we will load the data into a pandas dataframe, use select columns, and create vector embedding using azure open ai. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "openai.api_type = config[\"openai_api_type\"] \n",
    "openai.api_key = config['openai_api_key']\n",
    "openai.api_base = config['openai_api_base'] \n",
    "openai.api_version = config['openai_api_version'] \n",
    "\n",
    "\n",
    "def createEmbeddings(text):\n",
    "    response = openai.Embedding.create(input=text , engine=config[\"openai_deployment_embedding\"])\n",
    "    embeddings = response['data'][0]['embedding']\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "\n",
    "# Read data into a DataFrame\n",
    "df = pd.read_csv('../../DataSet/Reviews_small.csv')\n",
    "\n",
    "\n",
    "# Create a new column called 'embedding' in the DataFrame\n",
    "df['embedding'] = np.empty((len(df),), dtype=object)\n",
    "\n",
    "# Iterate over each row in the DataFrame and assign the concatenation and embeddings\n",
    "for index, row in df.iterrows():\n",
    "    product_id = row['ProductId']\n",
    "    score = row['Score']\n",
    "    text = row['Text']\n",
    "    \n",
    "    # Concatenate the desired columns\n",
    "    concat_text = f\"productid: {product_id} score: {score} text: {text}\"\n",
    "    \n",
    "    # Create embeddings using the provided function\n",
    "    embeddings = createEmbeddings(concat_text)\n",
    "    #print(embeddings)\n",
    "    \n",
    "    # Assign the embeddings to the 'embedding' column\n",
    "    df.at[index, 'embedding'] = embeddings\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will load the data frame data into the database for future retrieval. Please note the use of pgvector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The table 'food_reviews_vs2' exists in the database.\n",
      "You may drop previous table (see commented code above) if you want to re-insert reviews.\n"
     ]
    }
   ],
   "source": [
    "from pgvector.psycopg2 import register_vector\n",
    "from psycopg2 import Error\n",
    "from psycopg2 import sql\n",
    "# Establish a connection to the database\n",
    "connection = psycopg2.connect(conn_string)\n",
    "\n",
    "# Register 'pgvector' type for the 'embedding' column\n",
    "register_vector(connection)\n",
    "\n",
    "# Convert the DataFrame to a list of tuples for bulk insertion\n",
    "records = df.to_records(index=False)\n",
    "records_list = records.tolist()\n",
    "\n",
    "# Open a cursor to perform database operations\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Define the table name\n",
    "table_name = 'food_reviews_vs2'\n",
    "batch_size = 10\n",
    "# # Drop previous table of same name if one exists\n",
    "# cursor.execute(f\"DROP TABLE IF EXISTS {table_name};\")\n",
    "# print(\"Finished dropping table (if existed)\")\n",
    "# connection.commit()\n",
    "\n",
    "# Execute the query to check if the table exists\n",
    "cursor.execute(f\"SELECT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_name = '{table_name}');\")\n",
    "\n",
    "# Fetch the result\n",
    "exists = cursor.fetchone()[0]\n",
    "\n",
    "if exists:\n",
    "    print(f\"The table '{table_name}' exists in the database.\")\n",
    "    print(\"You may drop previous table (see commented code above) if you want to re-insert reviews.\")\n",
    "else:\n",
    "    print(f\"The table '{table_name}' does not exist in the database. Creating it now and inserting reviews ...\")\n",
    "    # Build a connection string from the variables\n",
    "    conn_string = \"host={0} user={1} dbname={2} password={3} sslmode={4}\".format(host, user, dbname, password, sslmode)\n",
    "\n",
    "    postgreSQL_pool = psycopg2.pool.SimpleConnectionPool(1, 20, conn_string)\n",
    "    if postgreSQL_pool:\n",
    "        print(\"Connection pool created successfully\")\n",
    "\n",
    "    # Use getconn() to get a connection from the connection pool\n",
    "    with postgreSQL_pool.getconn() as connection:\n",
    "        # Define the CREATE TABLE query\n",
    "        create_table_query = f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "            Id INTEGER PRIMARY KEY,\n",
    "            ProductId TEXT,\n",
    "            UserId TEXT,\n",
    "            ProfileName TEXT,\n",
    "            HelpfulnessNumerator INTEGER,\n",
    "            HelpfulnessDenominator INTEGER,\n",
    "            Score INTEGER,\n",
    "            Time INTEGER,\n",
    "            Summary TEXT,\n",
    "            Text TEXT,\n",
    "            Embedding VECTOR\n",
    "        );\n",
    "        \"\"\"\n",
    "\n",
    "        # Execute the CREATE TABLE query\n",
    "        cursor.execute(create_table_query)\n",
    "        connection.commit()\n",
    "\n",
    "        # Define the INSERT INTO query\n",
    "        insert_query = f\"INSERT INTO {table_name} (Id, ProductId, UserId, ProfileName, HelpfulnessNumerator, HelpfulnessDenominator, Score, Time, Summary, Text, embedding) \" \\\n",
    "                    f\"VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "        # Execute the INSERT INTO query for each row\n",
    "        cursor.executemany(insert_query, records_list)\n",
    "        connection.commit()\n",
    "        \n",
    "        # Execute the CREATE TABLE query\n",
    "        try:\n",
    "            with connection.cursor() as cursor:\n",
    "                cursor.execute(create_table_query)\n",
    "                connection.commit()\n",
    "                print(f\"Table {table_name} created successfully!\")\n",
    "        except (Exception, Error) as e:\n",
    "            print(f\"Error creating table {table_name}: {e}\")\n",
    "            connection.rollback()        \n",
    "        \n",
    "        \n",
    "        # Convert numpy.int32 to int in each row\n",
    "        records_list = [\n",
    "            tuple(int(value) if isinstance(value, np.int32) else value for value in record)\n",
    "            for record in records_list\n",
    "        ]\n",
    "\n",
    "        # Split the records list into batches\n",
    "        batches = [records_list[i: i + batch_size] for i in range(0, len(records_list), batch_size)]\n",
    "\n",
    "        # Iterate over each batch and perform bulk insert\n",
    "        count = 0\n",
    "        for batch in batches:\n",
    "            count += 1\n",
    "            print(f\"Inserting batch {count} into the table\")\n",
    "            try:\n",
    "                insert_query = sql.SQL(f\"INSERT INTO {table_name} (Id, ProductId, UserId, ProfileName, HelpfulnessNumerator, HelpfulnessDenominator, Score, Time, Summary, Text, Embedding) \" \\\n",
    "                                    f\"VALUES ({', '.join(['%s'] * len(batch[0]))})\")\n",
    "                \n",
    "                with connection.cursor() as cursor:\n",
    "                    cursor.executemany(insert_query, batch)\n",
    "                    connection.commit()\n",
    "            except (Exception, Error) as e:\n",
    "                print(f\"Error inserting batch into the table: {e}\")\n",
    "                connection.rollback()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items: (99,)\n",
      "Items ID: (1,)\n",
      "Items ID: (2,)\n",
      "Items ID: (3,)\n",
      "Items ID: (4,)\n",
      "Items ID: (5,)\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already established a connection and have a cursor object\n",
    "\n",
    "# Rollback the current transaction\n",
    "connection.rollback()\n",
    "cursor = connection.cursor()\n",
    "# Execute the SELECT statement\n",
    "try:\n",
    "    cursor.execute(f\"SELECT count(Id) FROM {table_name};\")\n",
    "    rows = cursor.fetchall()\n",
    "    for row in rows:\n",
    "        print(f\"Number of items: {row}\")\n",
    "except (Exception, Error) as e:\n",
    "    print(f\"Error executing SELECT statement: {e}\")\n",
    "    \n",
    "try:\n",
    "    cursor.execute(f\"SELECT Id FROM {table_name} limit 5;\")\n",
    "    rows = cursor.fetchall()\n",
    "    for row in rows:\n",
    "        print(f\"Items ID: {row}\")\n",
    "except (Exception, Error) as e:\n",
    "    print(f\"Error executing SELECT statement: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Asks a Question \n",
    "In this step, the code will convert the user's question to an embedding and then retieve the top K document chunks based on the users' question using the similarity. Please note that other similarity metrics can also be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "userQuestion = \"Great Taffy\"\n",
    "retrieve_k = 3 # for retrieving the top k reviews from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for the question and retrieve the top k document chunks\n",
    "questionEmbedding = createEmbeddings(userQuestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgvector.psycopg2 import register_vector\n",
    "\n",
    "connection = psycopg2.connect(conn_string)\n",
    "# Register 'pgvector' type for the 'embedding' column\n",
    "register_vector(connection)\n",
    "\n",
    "select_query = f\"SELECT id FROM {table_name} ORDER BY embedding <-> %s LIMIT 3\"\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(select_query, (np.array(questionEmbedding),))\n",
    "results = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 8, 7]\n"
     ]
    }
   ],
   "source": [
    "# Use the top k ids to retrieve the actual text from the database \n",
    "top_ids = []\n",
    "for i in range(len(results)):\n",
    "    top_ids.append(int(results[i][0]))\n",
    "\n",
    "print(top_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Search\n",
    "In this case, we will first filter based on id range, and then do similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgvector.psycopg2 import register_vector\n",
    "\n",
    "connection = psycopg2.connect(conn_string)\n",
    "# Register 'pgvector' type for the 'embedding' column\n",
    "register_vector(connection)\n",
    "id_low = 1\n",
    "id_high = 7\n",
    "select_query = f\"SELECT id FROM {table_name} where id BETWEEN {id_low} and {id_high} ORDER BY embedding <-> %s LIMIT 3\"\n",
    "cursor = connection.cursor()\n",
    "cursor.execute(select_query, (np.array(questionEmbedding),))\n",
    "results = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 7, 6]\n"
     ]
    }
   ],
   "source": [
    "# Use the top k ids to retrieve the actual text from the database \n",
    "top_ids = []\n",
    "for i in range(len(results)):\n",
    "    top_ids.append(int(results[i][0]))\n",
    "\n",
    "print(top_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note how the top ids are now different and within range."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve text from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('productid: B006K2ZZ7K score: 5 text: Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.',)\n",
      "('productid: B006K2ZZ7K score: 4 text: I got a wild hair for taffy and ordered this five pound bag. The taffy was all very enjoyable with many flavors: watermelon, root beer, melon, peppermint, grape, etc. My only complaint is there was a bit too much red/black licorice-flavored pieces (just not my particular favorites). Between me, my kids, and my husband, this lasted only two weeks! I would recommend this brand of taffy -- it was a delightful treat.',)\n",
      "(\"productid: B006K2ZZ7K score: 5 text: This saltwater taffy had great flavors and was very soft and chewy.  Each candy was individually wrapped well.  None of the candies were stuck together, which did happen in the expensive version, Fralinger's.  Would highly recommend this candy!  I served it at a beach-themed party and everyone loved it!\",)\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already established a connection and have a cursor object\n",
    "\n",
    "# Rollback the current transaction\n",
    "connection.rollback()\n",
    "\n",
    "format_ids = ', '.join(['%s'] * len(top_ids))\n",
    "\n",
    "sql = f\"SELECT CONCAT('productid: ', productid, ' ', 'score: ', score, ' ', 'text: ', text) AS concat FROM {table_name} WHERE id IN ({format_ids})\"\n",
    "\n",
    "# Execute the SELECT statement\n",
    "try:\n",
    "    cursor.execute(sql, top_ids)    \n",
    "    top_rows = cursor.fetchall()\n",
    "    for row in top_rows:\n",
    "        print(row)\n",
    "except (Exception, Error) as e:\n",
    "    print(f\"Error executing SELECT statement: {e}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIONAL: Offer Response to User's Question\n",
    "In order to offer a response, a user can either follow a simple prompting method as shown below or leverage more sophisticated ways used by other libraries, such as [langchain](https://python.langchain.com/en/latest/index.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompting directly using Azure Open AI service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a prompt template \n",
    "template = \"\"\"\n",
    "    context :{context}\n",
    "    Answer the question based on the context above. Provide the product id associated with the answer as well. If the\n",
    "    information to answer the question is not present in the given context then reply \"I don't know\".\n",
    "    Question: {query}\n",
    "    Answer: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "productid: B006K2ZZ7K score: 5 text: Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.\n",
      "productid: B006K2ZZ7K score: 4 text: I got a wild hair for taffy and ordered this five pound bag. The taffy was all very enjoyable with many flavors: watermelon, root beer, melon, peppermint, grape, etc. My only complaint is there was a bit too much red/black licorice-flavored pieces (just not my particular favorites). Between me, my kids, and my husband, this lasted only two weeks! I would recommend this brand of taffy -- it was a delightful treat.\n",
      "productid: B006K2ZZ7K score: 5 text: This saltwater taffy had great flavors and was very soft and chewy.  Each candy was individually wrapped well.  None of the candies were stuck together, which did happen in the expensive version, Fralinger's.  Would highly recommend this candy!  I served it at a beach-themed party and everyone loved it!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the context from the top_rows\n",
    "context = \"\"\n",
    "for row in top_rows:\n",
    "    context += row[0]\n",
    "    context += \"\\n\"\n",
    "    \n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great Taffy\n",
      "\n",
      "    context :productid: B006K2ZZ7K score: 5 text: Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.\n",
      "productid: B006K2ZZ7K score: 4 text: I got a wild hair for taffy and ordered this five pound bag. The taffy was all very enjoyable with many flavors: watermelon, root beer, melon, peppermint, grape, etc. My only complaint is there was a bit too much red/black licorice-flavored pieces (just not my particular favorites). Between me, my kids, and my husband, this lasted only two weeks! I would recommend this brand of taffy -- it was a delightful treat.\n",
      "productid: B006K2ZZ7K score: 5 text: This saltwater taffy had great flavors and was very soft and chewy.  Each candy was individually wrapped well.  None of the candies were stuck together, which did happen in the expensive version, Fralinger's.  Would highly recommend this candy!  I served it at a beach-themed party and everyone loved it!\n",
      "\n",
      "    Answer the question based on the context above. Provide the product id associated with the answer as well. If the\n",
      "    information to answer the question is not present in the given context then reply \"I don't know\".\n",
      "    Question: Great Taffy\n",
      "    Answer: \n"
     ]
    }
   ],
   "source": [
    "print(userQuestion)\n",
    "prompt = template.format(context=context, query=userQuestion)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt:  \n",
      "    context :productid: B006K2ZZ7K score: 5 text: Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.\n",
      "productid: B006K2ZZ7K score: 4 text: I got a wild hair for taffy and ordered this five pound bag. The taffy was all very enjoyable with many flavors: watermelon, root beer, melon, peppermint, grape, etc. My only complaint is there was a bit too much red/black licorice-flavored pieces (just not my particular favorites). Between me, my kids, and my husband, this lasted only two weeks! I would recommend this brand of taffy -- it was a delightful treat.\n",
      "productid: B006K2ZZ7K score: 5 text: This saltwater taffy had great flavors and was very soft and chewy.  Each candy was individually wrapped well.  None of the candies were stuck together, which did happen in the expensive version, Fralinger's.  Would highly recommend this candy!  I served it at a beach-themed party and everyone loved it!\n",
      "\n",
      "    Answer the question based on the context above. Provide the product id associated with the answer as well. If the\n",
      "    information to answer the question is not present in the given context then reply \"I don't know\".\n",
      "    Question: Great Taffy\n",
      "    Answer: \n",
      "~~~~~\n",
      "\n",
      "Productid: B006K2ZZ7K\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = openai.Completion.create(\n",
    "    engine= config[\"openai_deployment_completion\"],\n",
    "    prompt=prompt,\n",
    "    max_tokens=1024,\n",
    "    n=1,\n",
    "    stop=None,\n",
    "    temperature=1,\n",
    ")\n",
    "\n",
    "print(\"prompt: \", prompt)\n",
    "print('~~~~~')\n",
    "# print(\"response: \", response['choices'][0]['text'].replace('\\n', '').replace(' .', '.').strip())\n",
    "print(response['choices'][0]['text'])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
